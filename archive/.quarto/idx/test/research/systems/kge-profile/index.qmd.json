{"title":"Investigating Spatial-Temporal and Knowledge Graph Machine Learning Algorithms for Dominant Kernels & Potential Scope of Speedup","markdown":{"yaml":{"title":"Investigating Spatial-Temporal and Knowledge Graph Machine Learning Algorithms for Dominant Kernels & Potential Scope of Speedup","categories":["Spatio-Temporal Graph","Knowledge Graph Embedding","Profiling","CPU","Kernel","Graduate Course Project"],"description":"This project aims to identify the functions responsible for the long training times in Spatio-Temporal Graph Neural Networks and Knowledge Graph Embedding algorithms, comparing their frequency to optimize performance for larger graphs or real-time analysis.","date":"12/01/2023","image":"bottleneck.png"},"headingText":"Background","containsRefs":false,"markdown":"\n\n::: {.callout-note appearance=\"minimal\" title=\"Note\" icon=false collapse=false}\n\nGraduate Course Project\n\n* ENG 503 - Intro to Intelligent Systems with Dr. Ariful Azad\n\n\n[Slide](https://docs.google.com/presentation/d/198lUeo7WSKAmXfGlZyW8vGusNF_51PzmqvL_8jLO6bU/edit?usp=sharing){.badge .bg-primary .rounded-pill}\n\n:::\n\n![](bottleneck.png){.lightbox }\n\n\nSpatio-Temporal Graph Neural Networks (ST-GNNs) and Knowledge Graph Embedding (KGE) algorithms are state-of-the-art machine learning techniques for analyzing dynamic and relational data represented as graphs. These algorithms are widely applied in areas such as time-series prediction, recommendation systems, and knowledge extraction. Frameworks like PyTorch Geometric Temporal and TorchKGE are commonly used to implement these models.\n\nDespite their effectiveness, long training times remain a major challenge, particularly for large graphs or real-time applications. As graph size and complexity increase, the computational resources required for training grow significantly, limiting the scalability of these methods.\n\n## Methodology\n\nTo identify computational bottlenecks, we profiled several ST-GNN and KGE models on two different datasets. By analyzing the execution time of individual operations, we could pinpoint which functions dominate CPU computation during training. This profiling allows us to focus optimization efforts on the most impactful kernels rather than optimizing the entire model indiscriminately.\n\n## Findings\n\nFor Knowledge Graph Embedding models, profiling revealed three key internal PyTorch functions responsible for the majority of CPU time. These involve gradient computations for dense embeddings and vector normalization. Optimizing these functions could reduce CPU time by roughly 50%–60% for the corresponding datasets.\n\n(Done by my lab partner) For Spatio-Temporal Graph Neural Networks, three critical functions were identified that account for a substantial portion of total computation. Optimizing these kernels could lead to up to a 50% reduction in training time.\n\nThese findings demonstrate that targeted optimization of bottleneck kernels—rather than general code or sparse operations—can deliver significant performance improvements for graph-based models.","srcMarkdownNoYaml":"\n\n::: {.callout-note appearance=\"minimal\" title=\"Note\" icon=false collapse=false}\n\nGraduate Course Project\n\n* ENG 503 - Intro to Intelligent Systems with Dr. Ariful Azad\n\n\n[Slide](https://docs.google.com/presentation/d/198lUeo7WSKAmXfGlZyW8vGusNF_51PzmqvL_8jLO6bU/edit?usp=sharing){.badge .bg-primary .rounded-pill}\n\n:::\n\n![](bottleneck.png){.lightbox }\n\n## Background\n\nSpatio-Temporal Graph Neural Networks (ST-GNNs) and Knowledge Graph Embedding (KGE) algorithms are state-of-the-art machine learning techniques for analyzing dynamic and relational data represented as graphs. These algorithms are widely applied in areas such as time-series prediction, recommendation systems, and knowledge extraction. Frameworks like PyTorch Geometric Temporal and TorchKGE are commonly used to implement these models.\n\nDespite their effectiveness, long training times remain a major challenge, particularly for large graphs or real-time applications. As graph size and complexity increase, the computational resources required for training grow significantly, limiting the scalability of these methods.\n\n## Methodology\n\nTo identify computational bottlenecks, we profiled several ST-GNN and KGE models on two different datasets. By analyzing the execution time of individual operations, we could pinpoint which functions dominate CPU computation during training. This profiling allows us to focus optimization efforts on the most impactful kernels rather than optimizing the entire model indiscriminately.\n\n## Findings\n\nFor Knowledge Graph Embedding models, profiling revealed three key internal PyTorch functions responsible for the majority of CPU time. These involve gradient computations for dense embeddings and vector normalization. Optimizing these functions could reduce CPU time by roughly 50%–60% for the corresponding datasets.\n\n(Done by my lab partner) For Spatio-Temporal Graph Neural Networks, three critical functions were identified that account for a substantial portion of total computation. Optimizing these kernels could lead to up to a 50% reduction in training time.\n\nThese findings demonstrate that targeted optimization of bottleneck kernels—rather than general code or sparse operations—can deliver significant performance improvements for graph-based models."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.26","theme":["cosmo","brand"],"title":"Investigating Spatial-Temporal and Knowledge Graph Machine Learning Algorithms for Dominant Kernels & Potential Scope of Speedup","categories":["Spatio-Temporal Graph","Knowledge Graph Embedding","Profiling","CPU","Kernel","Graduate Course Project"],"description":"This project aims to identify the functions responsible for the long training times in Spatio-Temporal Graph Neural Networks and Knowledge Graph Embedding algorithms, comparing their frequency to optimize performance for larger graphs or real-time analysis.","date":"12/01/2023","image":"bottleneck.png"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}